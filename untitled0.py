# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1UP-ytetbPevgKeY8pjGg4IG5H9OI2Jnw
"""

from google.colab import files
upload=files.upload()

import pandas as pd

df = pd.read_csv("/IMDB Dataset.csv.zip")

total_reviews = len(df)
print(total_reviews)

sentiment_counts = df['sentiment'].value_counts()
print(sentiment_counts)

missing_values = df.isnull().sum()
print(missing_values)

df['review_length'] = df['review'].apply(len)
avg_review_length = df['review_length'].mean()
print(avg_review_length)

max_length = df['review_length'].max()
min_length = df['review_length'].min()
print("Maximum Length:", max_length)
print("Minimum Length:", min_length)

avg_length_by_sentiment = df.groupby('sentiment')['review_length'].mean()
print(avg_length_by_sentiment)

avg_length_by_sentiment = df.groupby('sentiment')['review_length'].mean()
print(avg_length_by_sentiment)

long_reviews_count = (df['review_length'] > 1000).sum()
print(long_reviews_count)

df['sentiment_num'] = df['sentiment'].map({'positive': 1, 'negative': 0})
print(df.head())

from collections import Counter
import re

all_words = ' '.join(df['review']).lower()
words = re.findall(r'\b\w+\b', all_words)
top_10_words = Counter(words).most_common(10)
print(top_10_words)

percentages = (sentiment_counts / total_reviews) * 100
print(percentages)

excellent_reviews = df[df['review'].str.contains(r'\bexcellent\b', case=False)]
print(excellent_reviews)

bad_acting_reviews = df[df['review'].str.contains('bad', case=False) & df['review'].str.contains('acting', case=False)]
print(bad_acting_reviews)

unique_words = len(set(words))
print(unique_words)

duplicate_count = df.duplicated(subset='review').sum()
print(duplicate_count)

df['cleaned_review'] = df['review'].str.replace(r'<.*?>', '', regex=True)
print(df.head())

positive_words = ' '.join(df[df['sentiment'] == 'positive']['cleaned_review']).lower()
positive_top_word = Counter(re.findall(r'\b\w+\b', positive_words)).most_common(1)
print(positive_top_word)

boring_reviews_count = df['review'].str.contains(r'\bboring\b', case=False).sum()
print(boring_reviews_count)

df['word_count'] = df['cleaned_review'].apply(lambda x: len(x.split()))
print(df.head())

longest_review = df.loc[df['word_count'].idxmax()]
print(longest_review)

import matplotlib.pyplot as plt

df['word_count'].hist(bins=50, figsize=(10,5))
plt.title('Histogram of Review Word Counts')
plt.xlabel('Number of Words')
plt.ylabel('Frequency')
plt.show()

import numpy as np

pos_words = np.concatenate(df[df['sentiment'] == 'positive']['review'].str.lower().str.split().values)
Counter(pos_words).most_common(5)
print(pos_words)
neg_words = np.concatenate(df[df['sentiment'] == 'negative']['review'].str.lower().str.split().values)
Counter(neg_words).most_common(5)
print(neg_words)